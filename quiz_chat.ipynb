{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string # to process standard python strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 dataLoader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vshekar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/vshekar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # first-time use only\n",
    "nltk.download('wordnet') # first-time use only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory\"\n",
      " 'No. 2: 1912 Olympian; football star at Carlisle Indian School; 6 MLB seasons with the Reds, Giants & Braves'\n",
      " 'The city of Yuma in this state has a record average of 4,055 hours of sunshine each year'\n",
      " ...\n",
      " 'In Penny Lane, where this \"Hellraiser\" grew up, the barber shaves another customer--then flays him alive!'\n",
      " 'From Ft. Sill, Okla. he made the plea, Arizona is my land, my home, my father\\'s land, to which I now ask to... return\"'\n",
      " 'A silent movie title includes the last name of this 18th c. statesman & favorite of Catherine the Great']\n"
     ]
    }
   ],
   "source": [
    "#clean.npy contains 2 columns ['question','answer']\n",
    "data = np.load('clean_data.npy')\n",
    "questions = data[:,0]\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmetizer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def create_lemtizedTokens(tokens):\n",
    "    return [lemmetizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def create_tokens(text):\n",
    "    if text not in result_dict:\n",
    "        result_dict[text] = create_lemtizedTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "    return result_dict[text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "TfidfVec = TfidfVectorizer(tokenizer=create_tokens, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "global sent_tokens,TfidfVec\n",
    "questions_vecs = TfidfVec.fit_transform(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_input):\n",
    "    response=''\n",
    "    question = [user_input]\n",
    "    question_vec = TfidfVec.transform(question)\n",
    "    vals = cosine_similarity(question_vec, questions_vecs)\n",
    "    idx=vals.argsort()[0]\n",
    "    similarity_scores = vals[0].tolist()\n",
    "    similarity_scores.sort()\n",
    "    highest_tfidf = similarity_scores[-1]\n",
    "    if(highest_tfidf==0):\n",
    "        response=response+\"sorry, cant answer\"\n",
    "        return response\n",
    "    else:\n",
    "        return data[idx[-1]][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello User\n",
      "p.s Type bye to exit\n",
      "Lillehammer winner who is Ukranian\n",
      "Bot: \n",
      "Oksana Baiul\n",
      "indian president\n",
      "Bot: \n",
      "Saddam Hussein\n",
      "bye\n",
      "BYE\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"Hello User\")\n",
    "print(\"p.s Type bye to exit\")\n",
    "while(True):\n",
    "    user_input=input().lower()\n",
    "    if user_input=='bye':\n",
    "        print('BYE')\n",
    "        break\n",
    "    else:\n",
    "        print(\"Bot: \\n\",end=\"\")\n",
    "        print(response(user_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
